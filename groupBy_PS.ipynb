{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "groupBy_PS",
      "provenance": [],
      "authorship_tag": "ABX9TyPgRPt/4NEIzF4rW0QFVNPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrarifahmed/pyspark/blob/main/groupBy_PS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilz_38b3FvCQ",
        "outputId": "d77af1ef-1a23-4c32-e961-31dbce8d1374"
      },
      "source": [
        " !nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May 20 16:32:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oIkCnHukU_Z"
      },
      "source": [
        "In this Video We will Cover,\n",
        "PySpark Dataframe,\n",
        "Reading The Dataset,\n",
        "Checking the Datatypes of the Column(Schema),\n",
        "Selecting Columns And Indexing,\n",
        "Check Describe option similar to Pandas,\n",
        "Adding Columns,\n",
        "Dropping columns,\n",
        "Renaming Columns,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWAU2G8akijP",
        "outputId": "43fc0389-a0be-4994-da30-023347d2135e"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 73kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 21.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=f1c85eea780cd7221b675b276dda7c8591893a7c61f0a18db12153f16103cbe9\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5atpBXN3JOv"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQhr_46N7YFD",
        "outputId": "f7763c84-05f5-4820-889a-a305563594d7"
      },
      "source": [
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUtk8Bv1ki0j"
      },
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d0UTiYdkYfB"
      },
      "source": [
        "spark=SparkSession.builder.appName('aggregate').getOrCreate()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzKx__Sb2yO3"
      },
      "source": [
        "df_pyspark=spark.read.option('header','true').csv('/content/drive/My Drive/Colab Notebooks/pyspark/test3.csv',inferSchema=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyqnJCFh2ySS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf34f01-08f0-4cfa-c3a0-0bb7efcc3b33"
      },
      "source": [
        "df_pyspark.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Departments: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT2Lrd7q_HxU",
        "outputId": "b52da839-7083-4a84-948c-2502b0f664ed"
      },
      "source": [
        "df_pyspark.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew2Gbdn7_IIf",
        "outputId": "49a09319-c8e9-406f-db76-ea7936283749"
      },
      "source": [
        "df_pyspark.describe().show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+-----------+-----------------+\n",
            "|summary| Name|Departments|           salary|\n",
            "+-------+-----+-----------+-----------------+\n",
            "|  count|   10|         10|               10|\n",
            "|   mean| null|       null|           7300.0|\n",
            "| stddev| null|       null|5396.500923952689|\n",
            "|    min|Krish|   Big Data|             2000|\n",
            "|    max|Sunny|        IOT|            20000|\n",
            "+-------+-----+-----------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX1mXCs92yWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04ba8ca-3e44-4455-dc63-68a37f7aa508"
      },
      "source": [
        "df_pyspark.filter(\"salary>=10000\").select('Name','Departments','salary').show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "+---------+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1TpeN-F_n6C",
        "outputId": "5b57f418-11f7-4d40-d003-7fa956ebb0cf"
      },
      "source": [
        "## Groupby\n",
        "### Grouped to find the maximum salary\n",
        "df_pyspark.groupBy('Name').sum().show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-----------+\n",
            "|     Name|sum(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      35000|\n",
            "|    Sunny|      12000|\n",
            "|    Krish|      19000|\n",
            "|   Mahesh|       7000|\n",
            "+---------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soN4YCF1_n9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987511f5-831c-4e6d-bfd4-50abac53c96d"
      },
      "source": [
        "## Groupby\n",
        "### Grouped to find the maximum salary\n",
        "df_pyspark.groupBy('Name').max('salary').show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-----------+\n",
            "|     Name|max(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      20000|\n",
            "|    Sunny|      10000|\n",
            "|    Krish|      10000|\n",
            "|   Mahesh|       4000|\n",
            "+---------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAOFr6Ey_oCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1867c4c2-183a-4546-d3c0-59ed17410656"
      },
      "source": [
        "## Groupby\n",
        "### Grouped to find the maximum salary based on Departments\n",
        "df_pyspark.groupBy('Departments').max('salary').show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-----------+\n",
            "| Departments|max(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      10000|\n",
            "|    Big Data|       5000|\n",
            "|Data Science|      20000|\n",
            "+------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5c2Sg2Qp6BO",
        "outputId": "27eae4cc-3b35-4636-a6d2-1bcd11344b52"
      },
      "source": [
        "## Groupby\n",
        "### Grouped to find the maximum salary based on Departments\n",
        "df_pyspark.groupBy('Departments').avg('salary').show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-----------+\n",
            "| Departments|avg(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0uJ_w_EqKCZ",
        "outputId": "74cb392f-946e-4b77-81cb-9ee8f821f71c"
      },
      "source": [
        "## Groupby\n",
        "### Grouped to find the sum of  salary based on Departments\n",
        "df_pyspark.groupBy('Departments').sum('salary').show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-----------+\n",
            "| Departments|sum(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      15000|\n",
            "|    Big Data|      15000|\n",
            "|Data Science|      43000|\n",
            "+------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}