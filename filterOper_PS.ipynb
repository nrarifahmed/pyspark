{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "filterOper_PS",
      "provenance": [],
      "authorship_tag": "ABX9TyNGHG8r1sYgluUbVEQU/DwQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrarifahmed/pyspark/blob/main/filterOper_PS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilz_38b3FvCQ",
        "outputId": "c2e4a151-2d1c-4bae-f48d-9797acb898fe"
      },
      "source": [
        " !nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May 20 16:17:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oIkCnHukU_Z"
      },
      "source": [
        "In this Video We will Cover,\n",
        "PySpark Dataframe,\n",
        "Reading The Dataset,\n",
        "Checking the Datatypes of the Column(Schema),\n",
        "Selecting Columns And Indexing,\n",
        "Check Describe option similar to Pandas,\n",
        "Adding Columns,\n",
        "Dropping columns,\n",
        "Renaming Columns,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWAU2G8akijP",
        "outputId": "077ef36b-483a-447b-890c-039962d568ac"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 76kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 20.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=f465725020810d34e059438dfca447d4d3f4e7e332fe3a57987f70f41b051889\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5atpBXN3JOv"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQhr_46N7YFD",
        "outputId": "c784ad75-5c97-410a-d69b-ad29665b0ece"
      },
      "source": [
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUtk8Bv1ki0j"
      },
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d0UTiYdkYfB"
      },
      "source": [
        "spark=SparkSession.builder.appName('Dataframe').getOrCreate()\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzKx__Sb2yO3"
      },
      "source": [
        "df_pyspark=spark.read.option('header','true').csv('/content/drive/My Drive/Colab Notebooks/pyspark/test1.csv',inferSchema=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyqnJCFh2ySS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc9caea-2fab-4926-e1bc-b2d7f491d4b4"
      },
      "source": [
        "df_pyspark.printSchema()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT2Lrd7q_HxU",
        "outputId": "a906ec79-f00a-43d0-9924-cc9367f16dfa"
      },
      "source": [
        "df_pyspark.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew2Gbdn7_IIf",
        "outputId": "bdc4d636-9675-450f-faa2-a2b5c11d299a"
      },
      "source": [
        "df_pyspark.describe().show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+------------------+-----------------+------------------+\n",
            "|summary|  Name|               age|       Experience|            Salary|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "|  count|     6|                 6|                6|                 6|\n",
            "|   mean|  null|26.333333333333332|4.666666666666667|21333.333333333332|\n",
            "| stddev|  null| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
            "|    min|Harsha|                21|                1|             15000|\n",
            "|    max| Sunny|                31|               10|             30000|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX1mXCs92yWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b71de1c-6a99-4a6e-f821-587a6935d652"
      },
      "source": [
        "df_pyspark.filter(\"Salary>=10000\").select('Name','Age','Salary').show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---+------+\n",
            "|     Name|Age|Salary|\n",
            "+---------+---+------+\n",
            "|    Krish| 31| 30000|\n",
            "|Sudhanshu| 30| 25000|\n",
            "|    Sunny| 29| 20000|\n",
            "|     Paul| 24| 20000|\n",
            "|   Harsha| 21| 15000|\n",
            "|  Shubham| 23| 18000|\n",
            "+---------+---+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1TpeN-F_n6C",
        "outputId": "c23bf100-6fc5-4765-df34-37be2a63d08a"
      },
      "source": [
        "df_pyspark.filter((df_pyspark['Salary'] >=10000) |\n",
        "                  (df_pyspark['Salary'] <=20000)).select('Name','Age','Salary','Experience').show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---+------+----------+\n",
            "|     Name|Age|Salary|Experience|\n",
            "+---------+---+------+----------+\n",
            "|    Krish| 31| 30000|        10|\n",
            "|Sudhanshu| 30| 25000|         8|\n",
            "|    Sunny| 29| 20000|         4|\n",
            "|     Paul| 24| 20000|         3|\n",
            "|   Harsha| 21| 15000|         1|\n",
            "|  Shubham| 23| 18000|         2|\n",
            "+---------+---+------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soN4YCF1_n9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535e449b-dd6a-4069-f3be-dbb821ffd07e"
      },
      "source": [
        "df_pyspark.filter((df_pyspark['Salary'] >=10000) &\n",
        "                  (df_pyspark['Salary'] <=20000)).select('Name','Age','Salary','Experience').show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+---+------+----------+\n",
            "|   Name|Age|Salary|Experience|\n",
            "+-------+---+------+----------+\n",
            "|  Sunny| 29| 20000|         4|\n",
            "|   Paul| 24| 20000|         3|\n",
            "| Harsha| 21| 15000|         1|\n",
            "|Shubham| 23| 18000|         2|\n",
            "+-------+---+------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAOFr6Ey_oCJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}